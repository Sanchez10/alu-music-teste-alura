# Alu Music - Teste de Desenvolvedor Python com LLMs

Este projeto foi desenvolvido como parte de um desafio t√©cnico Python com foco em LLMs. A aplica√ß√£o permite ingest√£o, classifica√ß√£o e an√°lise de coment√°rios sobre m√∫sicas, shows e √°lbuns. Ao longo do desenvolvimento, buscou-se atender requisitos funcionais e n√£o funcionais utilizando boas pr√°ticas de engenharia de software, integra√ß√£o com modelos de linguagem, CI/CD e ferramentas modernas de visualiza√ß√£o e persist√™ncia.

## ‚ú® Vis√£o Geral e Arquitetura

A arquitetura do projeto segue os princ√≠pios de separa√ß√£o de responsabilidades, com estrutura modular em Blueprints do Flask. Foi adotada uma estrutura MVC simplificada:

- **Models (SQLAlchemy):** Coment√°rio, ResumoSemanal e UserFake
- **Routes (Blueprints):** Coment√°rios, Dashboard, Relat√≥rio e Resumo
- **Services:** Classificador com LLM e rotina de gera√ß√£o de resumo semanal
- **Utils:** Middleware de autentica√ß√£o
- **Frontend:** Templates Jinja2 simples para dashboard privado

### üîß Trade-offs e Decis√µes T√©cnicas

- **LLM local (TinyLLaMA via Ollama):** Foi utilizado TinyLLaMA devido ao bom desempenho local e facilidade de uso com a API do Ollama. Como trade-off, temos menor capacidade sem GPU (apesar de que usando CUDAs fica muito melhor), mas mais controle e seguran√ßa dos dados.

- **Persist√™ncia com PostgreSQL via Docker:** Oferece confiabilidade e integra√ß√£o com SQLAlchemy. Optou-se por `docker-compose` para facilitar setup e isolar depend√™ncias.

- **Agendamento com APScheduler:** Executa a tarefa de resumo semanal sem depender de cron externo. Como cuidado, iniciamos o scheduler apenas fora do modo `TESTING`.

- **SMTP nativo:** Foi escolhido por simplicidade, mas poderia ser substitu√≠do por SendGrid para produ√ß√£o.

- **Autentica√ß√£o mista:** JWT para API e sess√£o com Flask-Login para dashboard. Essa separa√ß√£o atende m√∫ltiplos tipos de cliente (frontend web, ferramentas de API, etc).

- **CI/CD com GitHub Actions + Jenkins:** Combinou-se os dois para validar testes, cobertura e integra√ß√£o cont√≠nua. Jenkins atua como orquestrador que dispara os workflows do GitHub.

## üì¶ Tecnologias Utilizadas

- Python 3.10
- Flask + SQLAlchemy
- PostgreSQL (via Docker)
- Ollama + TinyLLaMA (modelo local)
- APScheduler (tarefas peri√≥dicas)
- SMTP nativo (envio de email)
- Chart.js (visualiza√ß√£o)
- Flask-Login + JWT
- Pytest + Coverage + GitHub Actions + Jenkins

## üöÄ Funcionalidades Implementadas

### üîé Classifica√ß√£o de Coment√°rios com LLM

- POST `/api/comentarios/` permite o envio de coment√°rios
- GET `/api/comentarios/` retorna todos os coment√°rios feitos
- A LLM classifica automaticamente:
  - **categoria** (ex: cr√≠tica, sugest√£o, elogio)
  - **tags_funcionalidades** (ex: artista, palco, som)
  - **confianca** (n√≠vel de certeza)

### üìä Relat√≥rio em Tempo Real

- Rota p√∫blica: `/relatorio/semana`
- Gr√°ficos interativos com Chart.js:
  - Tags mais citadas
  - Evolu√ß√£o de categorias nos √∫ltimos 7 dias
- Atualiza a cada 60 segundos com cache

### üîê 3. Dashboard Privado

- Acesso via login com senha
- Visualiza√ß√£o de coment√°rios com filtros
  - Filtro por categoria e tags
- Exporta√ß√£o de CSV dos dados vis√≠veis
- Protegido por sess√£o com Flask-Login

### üß† 4. Resumo Semanal com LLM

- Agrupa todos os coment√°rios da √∫ltima semana
- Gera resumo via LLM (TinyLLaMA)
- Armazena em tabela `resumos_semanal`
- Envia automaticamente por email

### ‚ùì 5. Insights com LLM (Q&A)

- Rota: `/insights/perguntar`
- Permite perguntar sobre os resumos anteriores
- Usa LLM para retornar resposta contextual baseada em m√∫ltiplos resumos armazenados

## üß™ Testes Automatizados

- Testes unit√°rios (Pytest)
- Cobertura com pytest-cov
- Separa√ß√£o por jobs no CI:
  - Testes unit√°rios
  - Testes de m√©tricas
  - Testes de integra√ß√£o

## Execu√ß√£o local

```bash
pytest --cov=app tests/
```

## üîÑ CI/CD com GitHub Actions + Jenkins

- `pytest` e `coverage` validados em cada push
- Jenkins orquestra o pipeline e monitora qualidade
- Fails no pull request se cobertura < 80% ou testes falharem

## üß∞ Setup do Projeto

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/Sanchez10/alu-music-teste-alura.git
cd alu-music-teste-alura
```

### 2. Crie o arquivo .env

```bash
DATABASE_URL=postgresql://user:pass@db:5432/alu_music
SECRET_KEY=supersecret
EMAIL_USER=joao.sanchez01@gmail.com
EMAIL_PASS=sua_senha_aqui
```

### 3. Suba os containers

```bash
docker compose up --build
```

### 4. Crie as tabelas do banco

```bash
docker compose run --rm web python -m scripts.create_tables.py
```

### 5. Rode as migrations

```bash
flask db upgrade
```

### 6. Gere token JWT (para testes)

```bash
docker compose run --rm web python -m scripts.generate_token.py
```

## üß† Modelo de LLM

A ideia √© utilizar uma LLM open source e que possa rodar localmente, ou seja, tendo um funcionamento inclusive offline. Para isso escolhi o Ollama, mais especificamente o motor "Tinyllama", e ent√£o devemos baix√°-la e rodar localmente.

https://ollama.com/download

```bash
ollama pull tinyllama
```

```bash
ollama serve
```

Como estamos usando docker √© necess√°rio abrir o WSL no Windows, caso ainda n√£o tenha instalado e descobri a refe√™ncia do IP da sua m√°quina host, para apontar corretamente a requisi√ß√£o da API do Ollama. Rode o seguinte commando no WSL

```bash
ip route | grep default
```

E ent√£o faremos uma integra√ß√£o para acessar o modelo via **HOST_IP:11434** usando Python

## Testes de API

### POST /api/comentarios/

Adiciona um novo coment√°rio.

**Header:**

```http
Authorization: Bearer <seu_token>
Content-Type: application/json
```

**Body:**

```http
{
    "texto": "Essa m√∫sica √© muito boa!"
}
```

### GET /api/comentarios/

Lista todos os coment√°rios existentes.

**Header:**

```http
Authorization: Bearer <seu_token>
Content-Type: application/json
```

## üìä Relat√≥rio Gr√°fico

- Dispon√≠vel em /relatorio/semana
- Atualiza√ß√£o din√¢mica a cada 60s

## üîê Dashboard Privado

- Login em /login
- Visualiza√ß√£o em /dashboard
- Exporta√ß√£o de CSV

  ### Acesse a dashboard (http://localhost:5000/login)

  Login com a senha: `admin123`

## üì¨ Email de Resumo Semanal

- Executado automaticamente via APScheduler
- Pode ser testado manualmente via:

```bash
flask shell
>>> from app.services.resumo import gerar_e_enviar_resumo
>>> gerar_e_enviar_resumo()
```

### Acesse o relat√≥rio semanal (http://localhost:5000/relatorio/semana)

## üìÅ Estrutura de Pastas

```bash
app/
‚îú‚îÄ‚îÄ models/              # Modelos SQLAlchemy
‚îú‚îÄ‚îÄ routes/              # Rotas Flask (Blueprints)
‚îú‚îÄ‚îÄ services/            # Classificador LLM (simulado)
‚îú‚îÄ‚îÄ utils/               # Autentica√ß√£o
scripts/                 # Scripts auxiliares
tests/                   # Testes (em breve)
```
